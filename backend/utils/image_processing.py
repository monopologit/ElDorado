import torch
from ultralytics import YOLO
from ultralytics.nn.tasks import DetectionModel
from ultralytics.nn.modules.conv import Conv as UltralyticsConv # Import Ultralytics Conv
from ultralytics.nn.modules.conv import Concat # Import Concat
from torch.nn.modules.container import Sequential, ModuleList # Import ModuleList
from torch.nn.modules.conv import Conv2d # Importar Conv2d
from torch.nn.modules.batchnorm import BatchNorm2d # Import BatchNorm2d
from torch.nn.modules.activation import SiLU # Import SiLU
from ultralytics.nn.modules.block import C2f, Bottleneck, SPPF # Import C2f, Bottleneck, and SPPF
from ultralytics.nn.modules.block import DFL # Import DFL
from torch.nn.modules.pooling import MaxPool2d # Import MaxPool2d
from torch.nn.modules.upsampling import Upsample # Import Upsample
from ultralytics.nn.modules.head import Detect # Import Detect
import os
import cv2
import numpy as np
from typing import Optional, Dict, Any # Add this line
from .ocr import extract_number_from_image # <--- A√±adir esta l√≠nea
from .number_grouping import detectar_numero_compuesto_desde_resultados, analizar_calidad_deteccion # Importar nueva funcionalidad

_PLACEHOLDER_CROPPED_IMAGE = np.zeros((1, 1, 3), dtype=np.uint8)

# Permitir la deserializaci√≥n de clases espec√≠ficas si es necesario
# Esto es crucial si el modelo .pt fue guardado con una versi√≥n de PyTorch
# que inclu√≠a estas clases directamente en el archivo de pesos.
# Solo a√±ade clases aqu√≠ si conf√≠as plenamente en el origen del archivo .pt.
try:
    # Lista de clases que pueden ser necesarias para tu modelo YOLOv8
    # Es posible que necesites a√±adir m√°s clases dependiendo de la arquitectura exacta
    # y c√≥mo fue guardado el modelo.
    safe_globals_list = [
        DetectionModel,
        Sequential,
        Conv2d,
        UltralyticsConv, # Add Ultralytics Conv to the list
        BatchNorm2d, # Add BatchNorm2d to the list
        SiLU, # Add SiLU to the list
        C2f, # Add C2f to the list
        ModuleList, # Add ModuleList to the list
        Bottleneck, # Add Bottleneck to the list
        SPPF, # Add SPPF to the list
        MaxPool2d, # Add MaxPool2d to the list
        Upsample, # Add Upsample to the list
        Concat, # Add Concat to the list - Corrected typo here
        Detect, # Add Detect to the list
        DFL # Add DFL to the list
    ]
    # A√±adir m√°s clases si aparecen errores similares para otras clases
    # Ejemplo: from another_module import AnotherClass
    # safe_globals_list.append(AnotherClass)

    torch.serialization.add_safe_globals(safe_globals_list)
    print(f"‚ÑπÔ∏è Clases seguras para deserializaci√≥n de PyTorch a√±adidas: {safe_globals_list}")
except AttributeError:
    print("‚ö†Ô∏è torch.serialization.add_safe_globals no est√° disponible. Esto es normal en versiones antiguas de PyTorch.")
except Exception as e:
    print(f"‚ùì Error al intentar a√±adir clases seguras para PyTorch: {e}")


class ImageProcessor:
    def __init__(self, model_path: Optional[str] = None): # Hacer model_path opcional
        """Inicializa el procesador de im√°genes con YOLOv8"""
        if model_path is None:            # Construir la ruta al modelo desde la ubicaci√≥n de este archivo (backend/utils/image_processing.py)
            # Sube tres niveles para llegar a la ra√≠z del proyecto (ElDorado)
            project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))              # Construye la ruta al modelo dentro de backend/models/numeros_enteros
            model_path = os.path.join(project_root, "backend", "models", "numeros_enteros", "yolo_model", "training", "best.pt")

        if not os.path.exists(model_path):            raise FileNotFoundError(
                f"El archivo del modelo YOLOv8 no se encontr√≥ en la ruta: {model_path}. "
                f"Verifica que el archivo \'best.pt\' exista en \'ElDorado\\backend\\models\\numeros_enteros\\yolo_model\\training\\\'.")
        
        print(f"‚ÑπÔ∏è Cargando modelo YOLO desde: {model_path}")
        self.model = YOLO(model_path)
        self.last_detection = None
        self.min_confidence = 0.15  # Reducido para mejorar detecci√≥n de n√∫meros enteros

    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """Preprocesa la imagen para mejorar la detecci√≥n"""
        # Convertir a escala de grises
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        # Mejorar contraste
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        # Volver a BGR para YOLO
        return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)

    def detect_objects(self, image: np.ndarray) -> Dict[str, Any]:
        """Detecta vagoneta, placa y modelo de ladrillo en la imagen"""
        if image is None:
            print("‚ùå Error Cr√≠tico: ImageProcessor.detect_objects recibi√≥ una imagen None.")
            # Devuelve detecciones vac√≠as para evitar m√°s errores si esto ocurre.
            return {'vagoneta': None, 'placa': None, 'ladrillo': None}

        # Preprocesar imagen
        processed_image = self.preprocess_image(image)
        
        # Realizar detecci√≥n con YOLOv8
        results = self.model(processed_image)[0]
        detections = {
            'vagoneta': None,
            'placa': None,
            'ladrillo': None
        }

        # Procesar resultados
        for box in results.boxes:
            confidence = float(box.conf[0])
            if confidence < self.min_confidence:
                continue

            class_id = int(box.cls[0])
            class_name = results.names[class_id]
            bbox = box.xyxy[0].cpu().numpy()
            
            detection_info = {'bbox': bbox, 'confidence': confidence}

            if class_name == 'vagoneta':
                detections['vagoneta'] = detection_info
            elif class_name == 'placa':
                detections['placa'] = detection_info
            elif 'ladrillo' in class_name: # Asumiendo que ladrillo tambi√©n podr√≠a querer confianza
                detections['ladrillo'] = {
                    'bbox': bbox,
                    'tipo': class_name,
                    'confidence': confidence
                }
        return detections

    def process_frame(self, frame: np.ndarray) -> Optional[Dict[str, Any]]:
        """Procesa un frame y retorna la informaci√≥n detectada"""
        # Detectar objetos
        detections = self.detect_objects(frame)
        
        if not detections['placa']:
            return None

        # Extraer y procesar n√∫mero de placa
        placa_bbox = detections['placa']
        placa_image = frame[
            int(placa_bbox[1]):int(placa_bbox[3]),
            int(placa_bbox[0]):int(placa_bbox[2])
        ]
        numero = extract_number_from_image(placa_image)

        if not numero:
            return None

        # Preparar resultado
        result = {
            'numero': numero,
            'confidence': float(detections['placa'][4]) if len(detections['placa']) > 4 else 0.0,
            'bbox': detections['placa'].tolist(),
        }        # Agregar informaci√≥n del modelo de ladrillo si se detect√≥
        if detections['ladrillo']:
            result['modelo_ladrillo'] = detections['ladrillo']['tipo']
        
        self.last_detection = result
        return result

    def get_last_detection(self) -> Optional[Dict[str, Any]]:
        """Retorna la √∫ltima detecci√≥n exitosa"""
        return self.last_detection

    def detect_calado_numbers_mejorado(self, image: np.ndarray, umbral_agrupacion: int = 50) -> Optional[Dict[str, Any]]:
        """
        Versi√≥n mejorada que detecta y agrupa n√∫meros individuales en n√∫meros compuestos.
        Integra la l√≥gica del c√≥digo de Colab con tu modelo existente.
        """
        try:
            # Verificar que la imagen es v√°lida
            if image is None:
                print("‚ùå Error: imagen es None")
                return None
                
            if not hasattr(image, 'ndim') or image.ndim != 3:
                print(f"‚ùå Error: imagen inv√°lida, ndim = {getattr(image, 'ndim', 'N/A')}")
                return None
                
            if image.size == 0:
                print("‚ùå Error: imagen vac√≠a")
                return None
            
            # Aplicar tu modelo actual de n√∫meros enteros
            results = self.model(image, conf=self.min_confidence)
            
            if not results or not results[0].boxes:
                return None
            
            # Usar la nueva funci√≥n de agrupaci√≥n
            frame_procesado, numero_compuesto, info_deteccion = detectar_numero_compuesto_desde_resultados(
                results, 
                image.copy(), 
                umbral_agrupacion
            )
            
            if numero_compuesto and info_deteccion:
                # Analizar calidad de la detecci√≥n
                analisis_calidad = analizar_calidad_deteccion(info_deteccion)
                
                # Agregar informaci√≥n adicional
                info_deteccion.update({
                    'numero': numero_compuesto,
                    'calidad': analisis_calidad,
                    'frame_procesado': frame_procesado is not None
                })
                
                self.last_detection = info_deteccion
                return info_deteccion
            
            return None
            
        except Exception as e:
            print(f"‚ùå Error en detect_calado_numbers_mejorado: {e}")
            import traceback
            traceback.print_exc()
            return None

    def detect_calado_numbers(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        Funci√≥n original mantenida como fallback
        """
        if image is None:
            print("‚ùå Error Cr√≠tico: ImageProcessor.detect_calado_numbers recibi√≥ una imagen None.")
            return None
        try:
            results = self.model(image, conf=self.min_confidence)[0]
            
            # Verificar si hay detecciones v√°lidas
            if results.boxes is None or len(results.boxes.xyxy) == 0:
                return None
            
            # Obtener la mejor detecci√≥n (mayor confianza)
            best_idx = torch.argmax(results.boxes.conf)
            best_box = results.boxes.xyxy[best_idx]
            best_conf = results.boxes.conf[best_idx]
            best_cls = results.boxes.cls[best_idx]
            
            # Extraer coordenadas del bounding box
            x1, y1, x2, y2 = map(int, best_box)
            
            # Recortar la regi√≥n de la placa
            cropped_image = image[y1:y2, x1:x2]
            
            if cropped_image.size == 0:
                return None
            
            # Aplicar OCR usando tu funci√≥n existente
            numero_detectado = extract_number_from_image(cropped_image)
            
            if numero_detectado:
                return {
                    'numero': numero_detectado,
                    'confidence': float(best_conf),
                    'bbox': (x1, y1, x2, y2),
                    'class_id': int(best_cls),
                    'cropped_image': cropped_image
                }
            
            return None
            
        except Exception as e:
            print(f"Error en detect_calado_numbers: {e}")
            return None
       

# Inicializar el procesador como singleton
processor = ImageProcessor()

def process_image(image: np.ndarray) -> Optional[Dict[str, Any]]:
    """Funci√≥n auxiliar para procesar una imagen"""
    return processor.process_frame(image)

def detectar_vagoneta_y_placa(image_data: np.ndarray) -> tuple[np.ndarray, Optional[np.ndarray], Optional[np.ndarray], Optional[str], Optional[float]]:
    """
    Detecta la vagoneta, la placa, extrae el n√∫mero de la placa, la imagen recortada de la placa y la confianza de detecci√≥n de la placa.

    Args:
        image_data (np.ndarray): Imagen a procesar (NumPy array).

    Returns:
        tuple: (cropped_placa_img, bbox_vagoneta, bbox_placa, numero_detectado, confianza)
               - cropped_placa_img (np.ndarray): Imagen recortada de la placa (or placeholder).
               - bbox_vagoneta (Optional[np.ndarray]): Bounding box de la vagoneta.
               - bbox_placa (Optional[np.ndarray]): Bounding box de la placa.
               - numero_detectado (Optional[str]): N√∫mero de placa detectado.
               - confianza_placa (Optional[float]): Confianza de la detecci√≥n de la placa.
    """
    image = image_data 
    if image is None or not hasattr(image, 'size') or image.size == 0: 
        print(f"Error: Imagen de entrada es None, no es un array numpy v√°lido o est√° vac√≠a en detectar_vagoneta_y_placa.")
        return _PLACEHOLDER_CROPPED_IMAGE, None, None, None, None

    detections = processor.detect_objects(image)

    bbox_vagoneta_info = detections.get('vagoneta')
    bbox_placa_info = detections.get('placa')
    
    bbox_vagoneta = bbox_vagoneta_info['bbox'] if bbox_vagoneta_info else None
    bbox_placa_coords = bbox_placa_info['bbox'] if bbox_placa_info else None
    placa_confidence = bbox_placa_info['confidence'] if bbox_placa_info else None
    
    actual_cropped_placa_img = None
    numero_detectado = None

    if bbox_placa_coords is not None:
        placa_y_start, placa_y_end = int(bbox_placa_coords[1]), int(bbox_placa_coords[3])
        placa_x_start, placa_x_end = int(bbox_placa_coords[0]), int(bbox_placa_coords[2])
        
        placa_y_start = max(0, placa_y_start)
        placa_x_start = max(0, placa_x_start)
        placa_y_end = min(image.shape[0], placa_y_end)
        placa_x_end = min(image.shape[1], placa_x_end)

        if placa_y_start < placa_y_end and placa_x_start < placa_x_end:
            placa_image_cropped = image[placa_y_start:placa_y_end, placa_x_start:placa_x_end]
            if placa_image_cropped.size > 0:
                actual_cropped_placa_img = placa_image_cropped
                numero_detectado = extract_number_from_image(actual_cropped_placa_img)
            else:
                print(f"Advertencia: El recorte de la placa result√≥ en una imagen vac√≠a.")
        else:
            print(f"Advertencia: Coordenadas de recorte de placa inv√°lidas.")
            
    return (actual_cropped_placa_img if actual_cropped_placa_img is not None else _PLACEHOLDER_CROPPED_IMAGE), \
           bbox_vagoneta, bbox_placa_coords, numero_detectado, placa_confidence

def detectar_modelo_ladrillo(image_path: str) -> Optional[str]:
    """
    Detecta el modelo de ladrillo en la imagen.

    Args:
        image_path (str): Ruta a la imagen a procesar.

    Returns:
        Optional[str]: El tipo de modelo de ladrillo detectado, o None si no se detecta.
    """
    image = cv2.imread(image_path)
    if image is None:
        print(f"Error: No se pudo cargar la imagen desde {image_path}")
        return None
    
    detections = processor.detect_objects(image)
    
    ladrillo_info = detections.get('ladrillo')
    if ladrillo_info and 'tipo' in ladrillo_info:
        return ladrillo_info['tipo']
    return None

def detect_calado_numbers(image: np.ndarray) -> Optional[Dict[str, Any]]:
    """
    Detecta n√∫meros calados directamente usando el modelo NumerosCalados
    
    Args:
        image (np.ndarray): Imagen a procesar
        
    Returns:
        Optional[Dict[str, Any]]: Informaci√≥n de detecci√≥n con n√∫mero, confianza y bbox
    """
    try:
        # Realizar detecci√≥n directa con YOLOv8 usando m√∫ltiples configuraciones
        # para maximizar las posibilidades de detecci√≥n
        best_detection = None
        best_confidence = 0.0
        
        # Configuraciones de detecci√≥n para probar
        detection_configs = [
            {"imgsz": 640, "conf": 0.05},   # Configuraci√≥n est√°ndar con umbral muy bajo
            {"imgsz": 1280, "conf": 0.05},  # Resoluci√≥n alta con umbral muy bajo
            {"imgsz": 320, "conf": 0.01},   # Resoluci√≥n baja con umbral ultra bajo
        ]
        
        print(f"üîç Probando {len(detection_configs)} configuraciones de detecci√≥n...")
        
        for i, config in enumerate(detection_configs):
            try:
                results = processor.model(image, **config)[0]
                
                total_detections = len(results.boxes) if results.boxes is not None else 0
                if total_detections > 0:
                    print(f"  Config {i+1} (imgsz={config['imgsz']}, conf={config['conf']}): {total_detections} detecciones")
                    
                    # Procesar detecciones de esta configuraci√≥n
                    for box in results.boxes:
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])
                        class_name = results.names[class_id]
                        bbox = box.xyxy[0].cpu().numpy()
                        
                        print(f"    Detecci√≥n: '{class_name}' - Confianza: {confidence:.3f}")
                        
                        # Quedarse con la detecci√≥n de mayor confianza
                        if confidence > best_confidence:
                            best_confidence = confidence
                            best_detection = {
                                'numero': class_name,
                                'confidence': confidence,
                                'bbox': bbox.tolist(),
                                'class_id': class_id,
                                'config_used': f"imgsz={config['imgsz']}_conf={config['conf']}"
                            }
                else:
                    print(f"  Config {i+1} (imgsz={config['imgsz']}, conf={config['conf']}): 0 detecciones")
                    
            except Exception as config_error:
                print(f"  Config {i+1}: Error - {config_error}")
                continue
        
        if best_detection:
            print(f"‚úÖ Mejor detecci√≥n: '{best_detection['numero']}' (confianza: {best_detection['confidence']:.3f}) usando {best_detection['config_used']}")
            return best_detection
        else:
            print("‚ö†Ô∏è No se detectaron n√∫meros calados en la imagen con ninguna configuraci√≥n")
            return None
            
    except Exception as e:
        print(f"‚ùå Error procesando imagen para n√∫meros calados: {e}")
        return None

def process_image_calados(image: np.ndarray) -> Optional[Dict[str, Any]]:
    """
    Funci√≥n principal para procesar im√°genes con el modelo de n√∫meros calados
    Reemplaza a process_image para el sistema de auto-captura
    """
    return detect_calado_numbers(image)

def detectar_vagoneta_y_placa_mejorado(image_data: np.ndarray, usar_agrupacion: bool = True) -> tuple[np.ndarray, Optional[np.ndarray], Optional[np.ndarray], Optional[str], Optional[float]]:
    """
    Versi√≥n mejorada que integra agrupaci√≥n de n√∫meros compuestos y devuelve confianza.
    
    Args:
        image_data (np.ndarray): Imagen a procesar (NumPy array).
        usar_agrupacion (bool): Si usar agrupaci√≥n de n√∫meros compuestos
    Returns:
        tuple: (cropped_placa_img, bbox_vagoneta, bbox_placa, numero_detectado, confianza)
               - cropped_placa_img (np.ndarray): Imagen recortada de la placa (or placeholder).
               - bbox_vagoneta (Optional[np.ndarray]): Bounding box de la vagoneta.
               - bbox_placa (Optional[np.ndarray]): Bounding box de la placa.
               - numero_detectado (Optional[str]): N√∫mero de placa detectado.
               - confianza (Optional[float]): Confianza de la detecci√≥n.
    """
    try:
        image = image_data 

        if image is None or not isinstance(image, np.ndarray): 
            print(f"‚ùå Error: image_data es None o no es un array numpy en detectar_vagoneta_y_placa_mejorado")
            return _PLACEHOLDER_CROPPED_IMAGE, None, None, None, None
            
        if not hasattr(image, 'ndim') or image.ndim != 3: 
            print(f"‚ùå Error: imagen inv√°lida (ndim != 3), ndim = {getattr(image, 'ndim', 'N/A')}")
            return _PLACEHOLDER_CROPPED_IMAGE, None, None, None, None
            
        if image.size == 0:
            print(f"‚ùå Error: imagen vac√≠a") 
            return _PLACEHOLDER_CROPPED_IMAGE, None, None, None, None

        if usar_agrupacion:
            resultado = processor.detect_calado_numbers_mejorado(image) 
            
            if resultado and resultado.get('numero'):
                bbox_placa_from_resultado = resultado.get('bbox')
                numero_detectado = resultado.get('numero')
                confianza = resultado.get('confidence') # Clave 'confidence' seg√∫n el log
                
                actual_cropped_placa_img = None
                bbox_vagoneta = None

                if bbox_placa_from_resultado is not None:
                    x1, y1, x2, y2 = map(int, bbox_placa_from_resultado)
                    x1, y1 = max(0, x1), max(0, y1)
                    x2 = min(image.shape[1], x2)
                    y2 = min(image.shape[0], y2)
                    
                    if y1 < y2 and x1 < x2:
                        actual_cropped_placa_img = image[y1:y2, x1:x2]
                    
                try:
                    detections_obj = processor.detect_objects(image) # Renamed to avoid conflict
                    vagoneta_info = detections_obj.get('vagoneta')
                    if vagoneta_info:
                        bbox_vagoneta = vagoneta_info['bbox']
                except Exception as det_error:
                    print(f"‚ö†Ô∏è Error detectando vagoneta: {det_error}")
                
                print(f"‚úÖ Detecci√≥n mejorada: {numero_detectado} (confianza: {confianza if confianza is not None else 'N/A'}, calidad: {resultado.get('calidad', {}).get('calidad', 'N/A')})")
                
                return (actual_cropped_placa_img if actual_cropped_placa_img is not None else _PLACEHOLDER_CROPPED_IMAGE), \
                       bbox_vagoneta, \
                       (np.array(bbox_placa_from_resultado) if bbox_placa_from_resultado is not None else None), \
                       numero_detectado, \
                       confianza
            
            print("‚ö†Ô∏è No se detect√≥ n√∫mero con agrupaci√≥n, intentando m√©todo original...")
            # Fallback ahora devuelve 5 elementos
            return detectar_vagoneta_y_placa(image) 
        
        # Si no usar_agrupacion, llamar al m√©todo original (que ahora tambi√©n devuelve 5 elementos)
        return detectar_vagoneta_y_placa(image) 
        
    except Exception as e:
        print(f"‚ùå Error en detecci√≥n mejorada: {e}, usando m√©todo original...")
        import traceback
        traceback.print_exc()
        try:
            # Fallback ahora devuelve 5 elementos
            return detectar_vagoneta_y_placa(image) 
        except Exception as fallback_error:
            print(f"‚ùå Error tambi√©n en m√©todo original (durante el fallback de detecci√≥n mejorada): {fallback_error}")
            traceback.print_exc() # <--- A√ëADIDO: Imprimir traza completa del error de fallback
            return _PLACEHOLDER_CROPPED_IMAGE, None, None, None, None
